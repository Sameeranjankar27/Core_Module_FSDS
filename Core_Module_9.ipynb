{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is the difference between a neuron and a neural network?\n",
        ">\n",
        "In the context of a neural network, a neuron is the most fundamental unit of processing. It's also called a perceptron. A neural network is based on the way a human brain works. So, we can say that it simulates the way the biological neurons signal to one another\n",
        "\n",
        "\n",
        "2. Can you explain the structure and components of a neuron?\n",
        ">\n",
        "A neuron has three main parts: dendrites, an axon, and a cell body or soma (see image below), which can be represented as the branches, roots and trunk of a tree, respectively. A dendrite (tree branch) is where a neuron receives input from other cells.\n",
        "\n",
        "\n",
        "3. Describe the architecture and functioning of a perceptron.\n",
        ">\n",
        "The perceptron model begins with multiplying all input values and their weights, then adds these values to create the weighted sum. Further, this weighted sum is applied to the activation function 'f' to obtain the desired output. This activation function is also known as the step function and is represented by 'f.\n",
        "\n",
        "\n",
        "4. What is the main difference between a perceptron and a multilayer perceptron?\n",
        ">\n",
        "A perceptron is a simple type of neural network that can learn to classify linearly separable patterns. It consists of a single layer of weighted inputs and a binary output. A multi-layer perceptron (MLP) is a more complex type of neural network that can learn to classify non-linearly separable patterns.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "5. Explain the concept of forward propagation in a neural network.\n",
        ">\n",
        "What is Forward Propagation in Neural Networks? Forward propagation is where input data is fed through a network, in a forward direction, to generate an output. The data is accepted by hidden layers and processed, as per the activation function, and moves to the successive layer.\n",
        "\n",
        "\n",
        "\n",
        "6. What is backpropagation, and why is it important in neural network training?\n",
        ">\n",
        "Backpropagation is a process involved in training a neural network. It involves taking the error rate of a forward propagation and feeding this loss backward through the neural network layers to fine-tune the weights. Backpropagation is the essence of neural net training.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "7. How does the chain rule relate to backpropagation in neural networks?\n",
        ">\n",
        "The chain rule can be generalised to multivariate functions, and represented by a tree diagram. The chain rule is applied extensively by the backpropagation algorithm in order to calculate the error gradient of the loss function with respect to each weight\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "8. What are loss functions, and what role do they play in neural networks?\n",
        ">\n",
        "A loss function is a function that compares the target and predicted output values; measures how well the neural network models the training data. When training, we aim to minimize this loss between the predicted and target outputs\n",
        "\n",
        "\n",
        "\n",
        "9. Can you give examples of different types of loss functions used in neural networks?\n",
        ">\n",
        "Some common loss functions in neural networks used for regression tasks include mean squared error (MSE) loss, mean squared logarithmic error (MSLE) loss, and mean absolute error (MAE) loss.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "10. Discuss the purpose and functioning of optimizers in neural networks.\n",
        ">\n",
        "An optimizer is an algorithm or function that adapts the neural network's attributes, like learning rate and weights. Hence, it assists in improving the accuracy and reduces the total loss. But it is a daunting task to choose the appropriate weights for the model.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "11. What is the exploding gradient problem, and how can it be mitigated?\n",
        ">\n",
        "These gradients are used to update the weights. If the gradients are large, the multiplication of these gradients will become huge over time. This results in the model being unable to learn and its behavior becomes unstable. This problem is called the exploding gradient problem.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "12. Explain the concept of the vanishing gradient problem and its impact on neural network training.\n",
        ">\n",
        "Vanishing gradient problem is a phenomenon that occurs during the training of deep neural networks, where the gradients that are used to update the network become extremely small or \"vanish\" as they are backpropogated from the output layers to the earlier layers.\n",
        "\n",
        "\n",
        "\n",
        "13. How does regularization help in preventing overfitting in neural networks?\n",
        ">\n",
        "Regularization is a technique that penalizes the coefficient. In an overfit model, the coefficients are generally inflated. Thus, Regularization adds penalties to the parameters and avoids them weigh heavily. The coefficients are added to the cost function of the linear equation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "14. Describe the concept of normalization in the context of neural networks.\n",
        ">\n",
        "Normalizing a set of data transforms the set of data to be on a similar scale. For machine learning models, our goal is usually to recenter and rescale our data such that is between 0 and 1 or -1 and 1, depending on the data itself\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "15. What are the commonly used activation functions in neural networks?\n",
        "Linear or Identity Activation Function.\n",
        "Non-linear Activation Function.\n",
        "Sigmoid or Logistic Activation Function.\n",
        "Tanh or hyperbolic tangent Activation Function.\n",
        "ReLU (Rectified Linear Unit) Activation Function.\n",
        "Leaky ReLU.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "16. Explain the concept of batch normalization and its advantages.\n",
        ">\n",
        "\n",
        "Batch normalization is a technique to standardize the inputs to a network, applied to ether the activations of a prior layer or inputs directly. Batch normalization accelerates training, in some cases by halving the epochs or better, and provides some regularization, reducing generalization error.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "17. Discuss the concept of weight initialization in neural networks and its importance.\n",
        ">\n",
        "Weight initialization is a procedure to set the weights of a neural network to small random values that define the starting point for the optimization (learning or training) of the neural network model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "18. Can you explain the role of momentum in optimization algorithms for neural networks?\n",
        ">\n",
        "Thus momentum in neural nets helps them get out of local minima points so that a more important global minimum is found. Too much of momentum may create issues as well as systems that are not stable may create oscillations that grow in magnitude, in such cases one needs to add decay terms and so on.\n",
        "\n",
        "\n",
        "\n",
        "19. What is the difference between L1 and L2 regularization in neural networks?\n",
        ">\n",
        "L1 regularization penalizes the sum of absolute values of the weights, whereas L2 regularization penalizes the sum of squares of the weights.\n",
        "\n",
        "\n",
        "\n",
        "20. How can early stopping be used as a regularization technique in neural networks?\n",
        ">\n",
        "Regularization by early stopping can be done either by dividing the dataset into training and test sets and then using cross-validation on the training set or by dividing the dataset into training, validation and test sets, in which case cross-validation, is not required. Here, the second case is analyzed.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "21. Describe the concept and application of dropout regularization in neural networks.\n",
        ">\n",
        "Dropout Regularization in Neural Networks: How it Works and ...\n",
        "Dropout regularization is a technique to prevent neural networks from overfitting. Dropout works by randomly disabling neurons and their corresponding connections. This prevents the network from relying too much on single neurons and forces all neurons to learn to generalize better.\n",
        "\n",
        "\n",
        "\n",
        "22. Explain the importance of learning rate in training neural networks.\n",
        ">\n",
        "In neural network models, the learning rate is a crucial hyperparameter that regulates the magnitude of weight updates applied during training. It is crucial in influencing the rate of convergence and the caliber of a model's answer.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "23. What are the challenges associated with training deep neural networks?\n",
        ">\n",
        "This can lead to several issues, such as the inability of the network to learn, poor generalization, and slow convergence. There are several common activation functions that can suffer from non-saturation, including the linear activation function and the sigmoid activation function.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "24. How does a convolutional neural network (CNN) differ from a regular neural network?\n",
        ">\n",
        "RNNs are better suited to analyzing temporal, sequential data, such as text or videos. A CNN has a different architecture from an RNN. CNNs are \"feed-forward neural networks\" that use filters and pooling layers, whereas RNNs feed results back into the network (more on this point below).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "25. Can you explain the purpose and functioning of pooling layers in CNNs?\n",
        ">\n",
        "Pooling layers are used to reduce the dimensions of the feature maps. Thus, it reduces the number of parameters to learn and the amount of computation performed in the network. The pooling layer summarises the features present in a region of the feature map generated by a convolution layer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "26. What is a recurrent neural network (RNN), and what are its applications?\n",
        ">\n",
        "Recurrent Neural Networks enable you to model time-dependent and sequential data problems, such as stock market prediction, machine translation, and text generation. You will find, however, RNN is hard to train because of the gradient problem. RNNs suffer from the problem of vanishing gradients.\n",
        "\n",
        "\n",
        "\n",
        "27. Describe the concept and benefits of long short-term memory (LSTM) networks.\n",
        ">\n",
        "Long short-term memory (LSTM) network is a recurrent neural network (RNN), aimed to deal with the vanishing gradient problem present in traditional RNNs. Its relative insensitivity to gap length is its advantage over other RNNs, hidden Markov models and other sequence learning methods. It aims to provide a short-term memory for RNN that can last thousands of timesteps, thus \"long short-term memory\". It is applicable to classification, processing and predicting data based on time series, such as in handwriting, speech recognition, machine translation, speech activity detection,robot control, video games,and healthcare.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "28. What are generative adversarial networks (GANs), and how do they work?\n",
        ">\n",
        "Generative Adversarial Networks (GANs) were introduced in 2014 by Ian J. Goodfellow and co-authors. GANs perform unsupervised learning tasks in machine learning. It consists of 2 models that automatically discover and learn the patterns in input data.\n",
        "\n",
        "\n",
        "\n",
        "29. Can you explain the purpose and functioning of autoencoder neural networks?\n",
        ">\n",
        "autoencoders are used to help reduce the noise in data. Through the process of compressing input data, encoding it, and then reconstructing it as an output, autoencoders allow you to reduce dimensionality and focus only on areas of real value.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "30. Discuss the concept and applications of self-organizing maps (SOMs) in neural networks.\n",
        ">\n",
        "Self-organizing maps, like most artificial neural networks, operate in two modes: training and mapping. First, training uses an input data set (the \"input space\") to generate a lower-dimensional representation of the input data (the \"map space\"). Second, mapping classifies additional input data using the generated map.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "31. How can neural networks be used for regression tasks?\n",
        ">\n",
        "The purpose of using Artificial Neural Networks for Regression over Linear Regression is that the linear regression can only learn the linear relationship between the features and target and therefore cannot learn the complex non-linear relationship\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "32. What are the challenges in training neural networks with large datasets?\n",
        ">\n",
        "Training a neural network involves using an optimization algorithm to find a set of weights to best map inputs to outputs. The problem is hard, not least because the error surface is non-convex and contains local minima, flat spots, and is highly multidimensional.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "33. Explain the concept of transfer learning in neural networks and its benefits.\n",
        ">\n",
        "Transfer learning is the reuse of a pre-trained model on a new problem. It's currently very popular in deep learning because it can train deep\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "34. How can neural networks be used for anomaly detection tasks?\n",
        ">\n",
        "Anomaly detection is identifying data points in data that don't fit the normal patterns. It can be useful to solve many problems including fraud detection, medical diagnosis, etc. Machine learning methods allow to automate anomaly detection and make it more effective, especially when large datasets are involved.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "35. Discuss the concept of model interpretability in neural networks.\n",
        ">\n",
        "DNN are based on simple mathematical operations, however, the combination of neurons with non-linear activations over several hidden layers is leading to models that cannot be evaluated with a mathematical formula. This property of the DNN is called a lack of transparency by Roscher\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "36. What are the advantages and disadvantages of deep learning compared to traditional machine learning algorithms?\n",
        ">\n",
        "Deep learning has several advantages over traditional machine learning methods, including automatic feature learning, handling large and complex data, improved performance, handling non-linear relationships, handling structured and unstructured data, predictive modeling, handling missing data, handling sequential data,\n",
        "\n",
        "\n",
        "\n",
        "37. Can you explain the concept of ensemble learning in the context of neural networks?\n",
        ">\n",
        "Ensemble learning combines the predictions from multiple neural network models to reduce the variance of predictions and reduce generalization error. Techniques for ensemble learning can be grouped by the element that is varied, such as training data, the model, and how predictions are combined\n",
        "\n",
        "\n",
        "\n",
        "38. How can neural networks be used for natural language processing (NLP) tasks?\n",
        ">\n",
        "Neural networks are also employed in natural language technology to enable computers to successfully perform the NLP process. In this way, texts or documents can be processed, information extracted and the meaning of the data determined. For example, chatbots or sentiment analysis for social media comments.\n",
        "\n",
        "\n",
        "\n",
        "39. Discuss the concept and applications of self-supervised learning in neural networks.\n",
        ">\n",
        "Face Detection\n",
        "\n",
        "This is one of the most common applications of SSL. Self-supervised learning is used in matching on screen faces with the input fed data. It is used for security purposes in mobile phones\n",
        "\n",
        "\n",
        "\n",
        "40. What are the challenges in training neural networks with imbalanced datasets?\n",
        ">\n",
        "What are the challenges with imbalanced class?\n",
        "Imbalanced classification is specifically hard because of the severely skewed class distribution and the unequal misclassification costs. The difficulty of imbalanced classification is compounded by properties such as dataset size, label noise, and data distribution.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "41. Explain the concept of adversarial attacks on neural networks and methods to mitigate them.\n",
        ">\n",
        "An adversarial attack is a method of making small modifications to the objects in such a way that the machine learning model begins to misclassify them. Neural networks (NN) are known to be vulnerable to such attacks. Research of adversarial methods historically started in the sphere of image recognition\n",
        "\n",
        "\n",
        "\n",
        "42. Can you discuss the trade-off between model complexity and generalization performance in neural networks?\n",
        ">\n",
        "One of the most important trade-offs is between complexity and generalization. Complexity refers to how well a model can fit the data and capture the nuances and patterns. Generalization refers to how well a model can perform on new and unseen data and avoid overfitting or underfitting.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "43. What are some techniques for handling missing data in neural networks?\n",
        ">\n",
        "Deleting Rows with missing values.\n",
        "Impute missing values for continuous variable.\n",
        "Impute missing values for categorical variable.\n",
        "Other Imputation Methods.\n",
        "Using Algorithms that support missing values.\n",
        "Prediction of missing values.\n",
        "\n",
        "\n",
        "\n",
        "44. Explain the concept and benefits of interpretability techniques like SHAP values and LIME in neural networks.\n",
        ">\n",
        "interpretability can lead to better decision-making because when a model is tested in the real world, those who developed it can observe its strengths and weaknesses. The chapter provides a plausible example of this, where a self-driving car mistakes snow for pavement and crashes into a cliff\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "45. How can neural networks be deployed on edge devices for real-time inference?\n",
        ">\n",
        "Edge AI is the implementation of artificial intelligence in an edge computing environment. That means AI computations are done at the edge of a given network, usually on the device where the data is created — like a camera or car — instead of in a centralized cloud computing facility or offsite data center\n",
        "\n",
        "\n",
        "\n",
        "46. Discuss the considerations and challenges in scaling neural network training on distributed systems.\n",
        ">\n",
        "Training a neural network involves using an optimization algorithm to find a set of weights to best map inputs to outputs. The problem is hard, not least because the error surface is non-convex and contains local minima, flat spots, and is highly multidimensional.\n",
        "\n",
        "\n",
        "\n",
        "47. What are the ethical implications of using neural networks in decision-making systems?\n",
        ">\n",
        "But there are many ethical challenges: Lack of transparency of AI tools: AI decisions are not always intelligible to humans. AI is not neutral: AI-based decisions are susceptible to inaccuracies, discriminatory outcomes, embedded or inserted bias. Surveillance practices for data gathering and privacy of court users.\n",
        "\n",
        "\n",
        "\n",
        "48. Can you explain the concept and applications of reinforcement learning in neural networks?\n",
        ">\n",
        "Reinforcement Learning is a trending data-driven approach for adaptive traffic signal control. These models are trained with the objective of learning a policy using a value function that optimally controls the traffic light based on the current status of the traffic\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "49. Discuss the impact of batch size in training neural networks\n",
        ">\n",
        "The batch size affects some indicators such as overall training time, training time per epoch, quality of the model, and similar. Usually, we chose the batch size as a power of two, in the range between 16 and 512. But generally, the size of 32 is a rule of thumb and a good initial choice.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "50. What are the current limitations of neural networks and areas for future research?\n",
        ">\n",
        "Neural networks are vulnerable to subtle perturbations or modifications of the input data, which can cause them to produce incorrect or misleading outputs. For example, adding a small amount of noise or changing a few pixels in an image can fool a neural network into misclassifying it as a different object\n"
      ],
      "metadata": {
        "id": "3QdmcXXbCcdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aagDC1XcCdDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8SjbNvyqCb7n"
      }
    }
  ]
}